# ğŸ™ï¸ VoiceBot with TTS & Echo ğŸ§

An interactive voice bot web application that supports both:
- **Text-to-Speech (TTS)** generation via Murf API
- **Echo audio playback** via in-browser recording

---

## ğŸ”¥ Features

âœ… Enter text and generate realistic audio using TTS  
âœ… Record voice and playback instantly (Echo Bot)  
âœ… FastAPI backend with REST API endpoint  
âœ… Simple frontend using HTML, CSS & JavaScript  
âœ… Spinner loading animation while TTS is generating  
âœ… Modular & beginner-friendly

---

## âš™ï¸ Tech Stack

| Layer       | Tech Used                 |
|-------------|---------------------------|
| Backend     | FastAPI (Python)          |
| TTS API     | Murf REST API             |
| Frontend    | HTML, CSS, JavaScript     |
| Audio Input | MediaRecorder API         |

---

## ğŸš€ Run Locally

### 1. Clone the repo

```bash
python -m venv venv
venv\Scripts\activate
pip install flask
python app.py
```
ğŸš€ More coming every day!

ğŸ¤ Day 2 Task: Connect to Murf.aiâ€™s REST API for Text-to-Speech!

ğŸš€ Built a FastAPI endpoint `/generate-audio` that accepts text and returns a URL to an audio file. API key secured with `.env`.

ğŸ§  Tools:
- FastAPI
- Murf.ai
- REST API
- Swagger UI (localhost:8000/docs)

Day 3: Play TTS Audio on Web UI

Todayâ€™s task was all about creating a seamless voice experience on the frontend! ğŸ—£ï¸âœ¨
 ğŸ”¹ I built a simple HTML page with a text input and a button.
 ğŸ”¹ When the user submits text, it makes a POST request to my FastAPI /generate-audio endpoint.
 ğŸ”¹ The backend calls Murfâ€™s REST TTS API to generate audio and sends back a playable URL.
 ğŸ”¹ The frontend receives that URL and plays the audio in an <audio> player element â€“ all dynamically handled using JavaScript!

ğŸ§  Skills Applied: RESTful API Integration (Murf TTS), FastAPI backend, CORS handling, Fetch API in JS,Audio playback on frontend
ğŸ” API keys stored securely in .env, keeping best practices in mind!
Canâ€™t wait to take this further with more advanced voice features!

Day 4 of the hashtag#30DaysOfAIVoiceAgents challenge is complete!
Todayâ€™s task: Build an Echo Bot using the MediaRecorder API!
Now my bot can record my voice and instantly play it back!ğŸ™ï¸
I created a full-stack application that:
ğŸ”¹ Accepts voice or text input 
ğŸ”¹ Uses Murf API to generate realistic TTS audio 
ğŸ”¹ Echoes back recorded audio via MediaRecorder 
ğŸ”¹ Built with FastAPI, JavaScript, and HTML/CSS 
ğŸ”¹ Fully interactive and plays audio directly in the browser!

Day 5: Send Audio to the Server 
Todayâ€™s task was about building a complete voice upload pipeline. After recording my voice using the Echo Bot I built earlier, I now upload that audio to my FastAPI backend using a new /upload-audio endpoint! 
hashtag#MurfAI hashtag#BuildWithMurf
ğŸ“Œ Features:
 âœ… Uses MediaRecorder to capture audio
 âœ… Uploads audio to backend after recording
 âœ… Stores audio in an /uploads directory
 âœ… Displays upload status and file details in the UI

Day 6: Transcribe Audio with AssemblyAI
Today, I integrated audio transcription into my voice agent! ğŸ”Šâ¡ï¸âœï¸
 âœ… Recorded audio using the browser
 âœ… Sent it to my FastAPI server
 âœ… Used AssemblyAI to transcribe audio in real time
 âœ… Displayed the transcription in the UI
ğŸ”§Tools Used: FastAPI, AssemblyAI Python SDK, JavaScript (MediaRecorder API), HTML/CSS